{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "DATA_SET_NAME = 'ml-20m'\n",
    "DATA_PATH = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    \"\"\"\n",
    "    Handle Progress Bar while Downloading\n",
    "    \"\"\"\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        \"\"\"\n",
    "        A hook function that will be called once on establishment of the network connection and\n",
    "        once after each block read thereafter.\n",
    "        \"\"\"\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "        \n",
    "def download_extract():\n",
    "    \"\"\"\n",
    "    Download and extract database\n",
    "    \"\"\"\n",
    "    url = 'http://files.grouplens.org/datasets/movielens/' + DATA_SET_NAME + '.zip'\n",
    "    \n",
    "    if not os.path.exists(DATA_PATH):\n",
    "        os.makedirs(DATA_PATH)\n",
    "    \n",
    "    file_path = os.path.join(DATA_PATH, DATA_SET_NAME + '.zip')\n",
    "    \n",
    "    # download data:\n",
    "    if not os.path.exists(file_path):\n",
    "        with DLProgress(unit='B', unit_scale=True, miniters=1, desc='Downloading ml-20m.zip') as pbar:\n",
    "            urlretrieve(\n",
    "                url,\n",
    "                file_path,\n",
    "                pbar.hook)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    print('Extracting data...')\n",
    "    with zipfile.ZipFile(file_path) as zf:\n",
    "        zf.extractall(DATA_PATH)\n",
    "\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies.csv: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('movies.csv: ')\n",
    "movies = pd.read_csv(os.path.join(DATA_PATH, DATA_SET_NAME,'movies.csv'),index_col=None)\n",
    "movies.describe()\n",
    "movies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings.csv: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112486027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1        2     3.5  1112486027\n",
       "1       1       29     3.5  1112484676\n",
       "2       1       32     3.5  1112484819\n",
       "3       1       47     3.5  1112484727\n",
       "4       1       50     3.5  1112484580"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('ratings.csv: ')\n",
    "ratings = pd.read_csv(os.path.join(DATA_PATH, DATA_SET_NAME,'ratings.csv'),index_col=None)\n",
    "ratings.describe()\n",
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags.csv: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4141</td>\n",
       "      <td>Mark Waters</td>\n",
       "      <td>1240597180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>208</td>\n",
       "      <td>dark hero</td>\n",
       "      <td>1368150078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>353</td>\n",
       "      <td>dark hero</td>\n",
       "      <td>1368150079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>521</td>\n",
       "      <td>noir thriller</td>\n",
       "      <td>1368149983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>592</td>\n",
       "      <td>dark hero</td>\n",
       "      <td>1368150078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId            tag   timestamp\n",
       "0      18     4141    Mark Waters  1240597180\n",
       "1      65      208      dark hero  1368150078\n",
       "2      65      353      dark hero  1368150079\n",
       "3      65      521  noir thriller  1368149983\n",
       "4      65      592      dark hero  1368150078"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('tags.csv: ')\n",
    "tags = pd.read_csv(os.path.join(DATA_PATH, DATA_SET_NAME,'tags.csv'),index_col=None)\n",
    "tags.describe()\n",
    "tags.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genome-tags.csv: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tagId</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>007 (series)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1920s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1930s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tagId           tag\n",
       "0      1           007\n",
       "1      2  007 (series)\n",
       "2      3  18th century\n",
       "3      4         1920s\n",
       "4      5         1930s"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('genome-tags.csv: ')\n",
    "genome_tags = pd.read_csv(os.path.join(DATA_PATH, DATA_SET_NAME,'genome-tags.csv'),index_col=None)\n",
    "genome_tags.describe()\n",
    "genome_tags.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genome-scores.csv: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>tagId</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.09675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.14675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  tagId  relevance\n",
       "0        1      1    0.02500\n",
       "1        1      2    0.02500\n",
       "2        1      3    0.05775\n",
       "3        1      4    0.09675\n",
       "4        1      5    0.14675"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('genome-scores.csv: ')\n",
    "genome_scores = pd.read_csv(os.path.join(DATA_PATH, DATA_SET_NAME,'genome-scores.csv'),index_col=None)\n",
    "genome_scores.describe()\n",
    "genome_scores.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Statistique simple sur les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of movies: 27278\n",
      "The number of ratings: 20000263\n",
      "\n",
      "min value of rating: 0.5\n",
      "max value of rating: 5.0\n",
      "\n",
      "The number of user in ratings.csv: 138493\n",
      "The minimum number of ratings per user in ratings.csv: 20\n",
      "The maximun number of ratings per user in ratings.csv: 9254\n",
      "\n",
      "The number of movies in ratings.csv: 26744\n",
      "The minimum number of ratings per movie in ratings.csv: 1\n",
      "The maximun number of ratings per movie in ratings.csv: 67310\n"
     ]
    }
   ],
   "source": [
    "print('The number of movies: {}'.format(movies.count()['movieId']))\n",
    "print('The number of ratings: {}'.format(ratings.count()['movieId']))\n",
    "\n",
    "print('')\n",
    "print('min value of rating: {}'.format(ratings['rating'].min()))\n",
    "print('max value of rating: {}'.format(ratings['rating'].max()))\n",
    "\n",
    "print('')\n",
    "ra = ratings.groupby(ratings['userId']).count()\n",
    "print('The number of user in ratings.csv: {}'.format(ra.count()[0]))\n",
    "print('The minimum number of ratings per user in ratings.csv: {}'.format(ra['movieId'].min()))\n",
    "print('The maximun number of ratings per user in ratings.csv: {}'.format(ra['movieId'].max()))\n",
    "\n",
    "print('')\n",
    "ra = ratings.groupby(ratings['movieId']).count()\n",
    "print('The number of movies in ratings.csv: {}'.format(ra.count()[0]))\n",
    "print('The minimum number of ratings per movie in ratings.csv: {}'.format(ra['userId'].min()))\n",
    "print('The maximun number of ratings per movie in ratings.csv: {}'.format(ra['userId'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tags in tags.csv: 465564\n",
      "The number of tags in genome-tags.csv: 1128\n",
      "\n",
      "The number of user in tags.csv: 7801\n",
      "The minimum number of tags per user in tags.csv: 1\n",
      "The maximun number of tags per user in tags.csv: 20356\n",
      "\n",
      "The number of movies in tags.csv: 19545\n",
      "The minimum number of tags per movie in tags.csv: 1\n",
      "The maximun number of tags per movie in tags.csv: 1994\n",
      "\n",
      "The number of tags in tags.csv but not in genome-tags.csv: 247993\n"
     ]
    }
   ],
   "source": [
    "print('The number of tags in tags.csv: {}'.format(tags.count()['userId']))\n",
    "print('The number of tags in genome-tags.csv: {}'.format(genome_tags.count()['tagId']))\n",
    "\n",
    "print('')\n",
    "ra = tags.groupby(tags['userId']).count()\n",
    "print('The number of user in tags.csv: {}'.format(ra.count()[0]))\n",
    "print('The minimum number of tags per user in tags.csv: {}'.format(ra['movieId'].min()))\n",
    "print('The maximun number of tags per user in tags.csv: {}'.format(ra['movieId'].max()))\n",
    "\n",
    "print('')\n",
    "ra = tags.groupby(tags['movieId']).count()\n",
    "print('The number of movies in tags.csv: {}'.format(ra.count()[0]))\n",
    "print('The minimum number of tags per movie in tags.csv: {}'.format(ra['userId'].min()))\n",
    "print('The maximun number of tags per movie in tags.csv: {}'.format(ra['userId'].max()))\n",
    "\n",
    "print('')\n",
    "tags_mer = pd.merge(tags, genome_tags, how='left', left_on='tag', right_on='tag')\n",
    "print('The number of tags in tags.csv but not in genome-tags.csv: {}'.format(tags_mer[(tags_mer['tagId'].isnull())].count()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of genome_scores.csv: 11709768\n",
      "max value of relevance from genome_scores.csv: 1.0\n",
      "min value of relevance from genome_scores.csv: 0.00024999999999997247\n",
      "\n",
      "The number of movies in genome_scores.csv: 10381\n",
      "The minimum number of tags per movie in genome_scores.csv: 1128\n",
      "The maximun number of tags per movie in genome_scores.csv: 1128\n"
     ]
    }
   ],
   "source": [
    "print('The length of genome_scores.csv: {}'.format(genome_scores.count()['movieId']))\n",
    "print('max value of relevance from genome_scores.csv: {}'.format(genome_scores['relevance'].max()))\n",
    "print('min value of relevance from genome_scores.csv: {}'.format(genome_scores['relevance'].min()))\n",
    "\n",
    "print('')\n",
    "ra = genome_scores.groupby(genome_scores['movieId']).count()\n",
    "print('The number of movies in genome_scores.csv: {}'.format(ra.count()[0]))\n",
    "print('The minimum number of tags per movie in genome_scores.csv: {}'.format(ra['tagId'].min()))\n",
    "print('The maximun number of tags per movie in genome_scores.csv: {}'.format(ra['tagId'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies in both genome_scores.csv and ratings.csv: 10370. Take up 53.0% of ratings.csv\n",
      "Number of ratings where its movieId in genome_scores.csv: 19800443. Take up 99.0% of ratings.csv\n",
      "\n",
      "138493 users rate the movies appearing in both genome_scores.csv and ratings.csv. Take up 100.0% of ratings.csv\n",
      "Minimum number of ratings per user for the movies appearing in both genome_scores.csv and ratings.csv: 13\n"
     ]
    }
   ],
   "source": [
    "# Analysis the relevant data of movies in both genome_scores.csv and ratings.csv:\n",
    "\n",
    "genome_scores_group = genome_scores.groupby(genome_scores['movieId']).mean()\n",
    "ratings_group = ratings.groupby(ratings['movieId']).mean()\n",
    "rat_ge_merge = pd.merge(ratings_group, genome_scores_group, how='inner', left_on='movieId', right_on='movieId')\n",
    "number = rat_ge_merge.count()[0]\n",
    "print('Number of movies in both genome_scores.csv and ratings.csv: {}. Take up {}% of ratings.csv'\\\n",
    "      .format(number, round(number/19545*100)))\n",
    "\n",
    "ratings_genome_merge = pd.merge(ratings, genome_scores_group, how='inner', left_on='movieId', right_on='movieId')\n",
    "number = ratings_genome_merge.count()[0]\n",
    "print('Number of ratings where its movieId in genome_scores.csv: {}. Take up {}% of ratings.csv'\\\n",
    "      .format(number, round(number/20000263*100)))\n",
    "\n",
    "print('')\n",
    "ra = ratings_genome_merge.groupby(ratings_genome_merge['userId']).count()\n",
    "number = ra.count()[0]\n",
    "print('{} users rate the movies appearing in both genome_scores.csv and ratings.csv. Take up {}% of ratings.csv'\\\n",
    "      .format(number, round(number/138493*100)))\n",
    "print('Minimum number of ratings per user for the movies appearing in both genome_scores.csv and ratings.csv: {}'.format(ra['movieId'].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypotheses et model de l'apprentissage automatique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothèse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Les balises de genome-tags.csv constituent l'ensemble complet des espaces vectoriels de balises. Les autres balises ne figurant pas dans génome-tags.csv sont des combinaisons linéaires de balises dans le génome-tags.csv.\n",
    "2-La fonctionnalité des films peut être parfaitement représentée par des balises dans genome-tags.csv, telles que le vecteur de pertinence dans genome_scores.csv.\n",
    "Le vecteur de pertinence dans genome_scores.csv est correct et peut représenter la fonctionnalité de films.\n",
    "3- Ignorer la qualité des films.\n",
    "4-Nous ne pouvons pas obtenir d'autres informations sur les films en dehors de l'ensemble de données. Donc, nous n'utilisons pas links.csv.\n",
    "5- La durée de sortie des films n’affecte pas.\n",
    "6- L'horodatage dans ratings.csv: et tags.csv n'affecte pas."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Definition du Problème"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation de données d'entrainement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data (You should run last code cell to get 'ratings_genome_merge')\n",
    "# The first column of features is userId, the next is movieId.\n",
    "# The only one column of target is rating.\n",
    "\n",
    "remove_fields = ['timestamp','tagId','relevance','rating']\n",
    "target = ratings_genome_merge['rating']\n",
    "feature = ratings_genome_merge.drop(remove_fields, axis=1)\n",
    "features = feature.values\n",
    "target = target.values\n",
    "\n",
    "genome_scores_dict = {}\n",
    "for i in range(10381):\n",
    "    m_id = -1\n",
    "    vec = []\n",
    "    for j in range(1128):\n",
    "        index = j + i * 1128\n",
    "        if m_id < 0:\n",
    "            m_id = genome_scores['movieId'][index]\n",
    "        assert genome_scores['movieId'][index] == m_id\n",
    "        assert genome_scores['tagId'][index] == j + 1\n",
    "        vec.append(genome_scores['relevance'][index])\n",
    "    genome_scores_dict[str(m_id)] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.86% users in test set (138294 users)\n",
      "100.0% users in training set (138493 users)\n"
     ]
    }
   ],
   "source": [
    "# Actually, using train_test_split in here is not best. \n",
    "# The better method should split the data according the userId, which make sure every user is in the test set.\n",
    "# But here, let us make it easier and quickly ( We have already include 99.86% users).\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_features,test_features, train_target, test_target = train_test_split(features,  \n",
    "                                                           target,  \n",
    "                                                           test_size = 0.2,  \n",
    "                                                           random_state = 0)\n",
    "\n",
    "dict_t = {}\n",
    "dict_t['userId'] = test_features[:,0]\n",
    "dict_t['movieId'] = test_features[:,1]\n",
    "pd_data = pd.DataFrame.from_dict(dict_t)\n",
    "user_test = pd_data.groupby(pd_data['userId']).count().count()[0]\n",
    "\n",
    "print('{}% users in test set ({} users)'.format(round(user_test/138493*100, 2), user_test ))\n",
    "\n",
    "dict_t = {}\n",
    "dict_t['userId'] = train_features[:,0]\n",
    "dict_t['movieId'] = train_features[:,1]\n",
    "pd_data = pd.DataFrame.from_dict(dict_t)\n",
    "user_train = pd_data.groupby(pd_data['userId']).count().count()[0]\n",
    "\n",
    "print('{}% users in training set ({} users)'.format(round(user_train/138493*100, 2), user_train ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocess data to './data/verify_assumption.data'\n",
    "pickle.dump((train_features, test_features, train_target, test_target, genome_scores_dict), open('./data/verify_assumption.data', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocess data from './data/verify_assumption.data'\n",
    "train_features, test_features, train_target, test_target, genome_scores_dict = pickle.load(open('./data/verify_assumption.data', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# les paramettres du model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 768  # batch size \"taille du lot\"\n",
    "lr = 1e-3         # learning rate \"taux d'apprentissage\"\n",
    "feature_dim = 512 # Dimension of movie or user feature vector 'Dimension du film ou du vecteur de fonctionnalités utilisateur'\n",
    "Epoch = 6         # train epoch \"époque du train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Verify_Assumption_Model(nn.Module):\n",
    "    \"\"\"The whole model\"\"\"\n",
    "    def __init__(self):\n",
    "        super(Verify_Assumption_Model, self).__init__()\n",
    "        self.emb_user = nn.Embedding(138493 + 1, 512, # use ratings['userId'].max()+1 instead of 138493+1 is better\n",
    "                            padding_idx=0)\n",
    "        \n",
    "        self.movie_transfrom = nn.Sequential(\n",
    "            nn.Linear(1128, 512),\n",
    "            nn.Tanh(), # activation function can not be the final layer of Sequential. But it can be the first one.\n",
    "            nn.Linear(512, 512)\n",
    "        )\n",
    "    \n",
    "    def forward(self, userId, movieVector):\n",
    "        v_user  = self.emb_user(userId)\n",
    "        v_movie = self.movie_transfrom(movieVector)\n",
    "        v_user.unsqueeze_(1)\n",
    "        v_movie.unsqueeze_(2)\n",
    "        return torch.bmm(v_user,v_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (38) : no CUDA-capable device is detected at /opt/conda/conda-bld/pytorch_1556653183467/work/aten/src/THC/THCGeneral.cpp:51",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-24ecf3ecb99f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVerify_Assumption_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TPE_test/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TPE_test/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TPE_test/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TPE_test/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TPE_test/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    162\u001b[0m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0m_cudart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudaGetErrorName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (38) : no CUDA-capable device is detected at /opt/conda/conda-bld/pytorch_1556653183467/work/aten/src/THC/THCGeneral.cpp:51"
     ]
    }
   ],
   "source": [
    "len_train_features = len(train_features)\n",
    "index = 0\n",
    "model = Verify_Assumption_Model()\n",
    "model.cuda()\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduce=False, size_average=False)\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                               lr=lr, weight_decay=0)\n",
    "losses = {'train':[], 'test':[]}\n",
    "\n",
    "for epoch_i in range(Epoch):\n",
    "    index = 0\n",
    "    while index <= len_train_features:\n",
    "        index_end = index + batch_size\n",
    "        if index_end >= len_train_features:\n",
    "            batch_train = train_features[index:len_train_features]\n",
    "            batch_train_target = train_target[index:len_train_features]\n",
    "        else:\n",
    "            batch_train = train_features[index:index_end]\n",
    "            batch_train_target = train_target[index:index_end]\n",
    "\n",
    "        #assert len(batch_train) == len(batch_train_target)\n",
    "\n",
    "        userId = batch_train[:,0]\n",
    "        movieId = batch_train[:,1]\n",
    "        movie_vec = []\n",
    "        for i in range(len(movieId)):\n",
    "            movie_vec.append(genome_scores_dict[str(movieId[i])])\n",
    "\n",
    "\n",
    "        rating = model(torch.tensor(userId, requires_grad = False).cuda(),torch.tensor(movie_vec, requires_grad = False).cuda())\n",
    "        rating = rating.squeeze_(1).squeeze_(1)\n",
    "        loss = sum(loss_fn(rating,torch.tensor(batch_train_target,dtype=torch.float32,requires_grad = False).cuda()))\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        losses['train'].append(loss.detach().cpu().numpy())\n",
    "        opt.step()\n",
    "        if len(losses['train']) % 500 == 0:\n",
    "            print('Epoch {:>3} Batch {:>4}/15840354   train_loss = {:.3f}'.format(\n",
    "                        epoch_i,\n",
    "                        index,\n",
    "                        losses['train'][len(losses['train'])-1]))\n",
    "        index += batch_size\n",
    "        \n",
    "    #############################test#############################\n",
    "    \n",
    "    len_test_features = len(test_features)\n",
    "    index = 0\n",
    "\n",
    "    while index <= len_test_features:\n",
    "        index_end = index + batch_size\n",
    "        if index_end >= len_train_features:\n",
    "            batch_train = test_features[index:len_train_features]\n",
    "            batch_train_target = test_target[index:len_train_features]\n",
    "        else:\n",
    "            batch_train = test_features[index:index_end]\n",
    "            batch_train_target = test_target[index:index_end]\n",
    "\n",
    "        #assert len(batch_train) == len(batch_train_target)\n",
    "\n",
    "        userId = batch_train[:,0]\n",
    "        movieId = batch_train[:,1]\n",
    "        movie_vec = []\n",
    "        for i in range(len(movieId)):\n",
    "            movie_vec.append(genome_scores_dict[str(movieId[i])])\n",
    "\n",
    "\n",
    "        rating = model(torch.tensor(userId, requires_grad = False).cuda(),torch.tensor(movie_vec, requires_grad = False).cuda())\n",
    "        rating = rating.squeeze_(1).squeeze_(1)\n",
    "        loss = sum(loss_fn(rating,torch.tensor(batch_train_target,dtype=torch.float32,requires_grad = False).cuda()))\n",
    "\n",
    "        losses['test'].append(loss.detach().cpu().numpy())\n",
    "        if len(losses['test']) % 500 == 0:\n",
    "            print('Epoch {:>3} Batch {:>4}/3960089   test_loss = {:.3f}'.format(\n",
    "                        epoch_i,\n",
    "                        index,\n",
    "                        losses['test'][len(losses['test'])-1]))\n",
    "        index += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
